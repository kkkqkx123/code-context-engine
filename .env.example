# Database Configuration
# Qdrant Configuration - Connection
QDRANT_HOST = 127.0.0.1
QDRANT_PORT = 6333

# NebulaGraph Configuration - Connection(后续会替换为我自己的图数据库)
NEBULA_ENABLED = false
NEBULA_HOST = 127.0.0.1
NEBULA_PORT = 9669
NEBULA_USERNAME = root
NEBULA_PASSWORD = nebula


# Project Management Configuration
PROJECT_ALLOW_REINDEX = true

# Embedding Configuration
EMBEDDING_PROVIDER = siliconflow
# 可选：
#  - openai
#  - ollama
#  - gemini
#  - mistral
#  - siliconflow (默认)
#  - custom1
#  - custom2
#  - custom3

# Skip unavailable provider checks to reduce unnecessary network requests
# Set to 'true' to skip checks for providers that are known to be unavailable
SKIP_UNAVAILABLE_PROVIDER_CHECKS = true

# Embedding Provider Enable/Disable (Set to 'false' to disable a provider)
OPENAI_ENABLED = false
OLLAMA_ENABLED = false
GEMINI_ENABLED = false
MISTRAL_ENABLED = false
SILICONFLOW_ENABLED = true
CUSTOM1_ENABLED = false
CUSTOM2_ENABLED = false
CUSTOM3_ENABLED = false

OPENAI_BASE_URL = https://api.openai.com
OPENAI_API_KEY = your-openai-api-key-here
OPENAI_MODEL = text-embedding-ada-002
OPENAI_DIMENSIONS = 1536

# Alternative embedding providers
OLLAMA_BASE_URL = http://localhost:11434
OLLAMA_MODEL = nomic-embed-text
OLLAMA_DIMENSIONS = 768

GEMINI_API_KEY = your-gemini-api-key-here
GEMINI_BASE_URL = https://generativelanguage.googleapis.com
GEMINI_MODEL = embedding-001
GEMINI_DIMENSIONS = 768

MISTRAL_API_KEY = your-mistral-api-key-here
MISTRAL_BASE_URL = https://api.mistral.ai
MISTRAL_MODEL = mistral-embed
MISTRAL_DIMENSIONS = 1024

SILICONFLOW_API_KEY = your-siliconflow-api-key-here
SILICONFLOW_BASE_URL = https://api.siliconflow.cn/v1
SILICONFLOW_MODEL = BAAI/bge-m3
SILICONFLOW_DIMENSIONS = 1024

# Custom embedder configurations (set your URLs in .env file)
CUSTOM_CUSTOM1_API_KEY = your-custom1-api-key-here
CUSTOM_CUSTOM1_BASE_URL = 
CUSTOM_CUSTOM1_MODEL = your-custom1-model-here
CUSTOM_CUSTOM1_DIMENSIONS = 768

CUSTOM_CUSTOM2_API_KEY = your-custom2-api-key-here
CUSTOM_CUSTOM2_BASE_URL = 
CUSTOM_CUSTOM2_MODEL = your-custom2-model-here
CUSTOM_CUSTOM2_DIMENSIONS = 768

CUSTOM_CUSTOM3_API_KEY = your-custom3-api-key-here
CUSTOM_CUSTOM3_BASE_URL = 
CUSTOM_CUSTOM3_MODEL = your-custom3-model-here
CUSTOM_CUSTOM3_DIMENSIONS = 768

# Embedding Batch Configuration
# Global embedding batch size limit (default: 50)
EMBEDDING_BATCH_SIZE = 50
# Provider-specific batch size limits
EMBEDDING_PROVIDER_OPENAI_BATCH_SIZE = 2048
EMBEDDING_PROVIDER_SILICONFLOW_BATCH_SIZE = 64
EMBEDDING_PROVIDER_OLLAMA_BATCH_SIZE = 128
EMBEDDING_PROVIDER_GEMINI_BATCH_SIZE = 100
EMBEDDING_PROVIDER_MISTRAL_BATCH_SIZE = 512
EMBEDDING_PROVIDER_CUSTOM1_BATCH_SIZE = 100
EMBEDDING_PROVIDER_CUSTOM2_BATCH_SIZE = 100
EMBEDDING_PROVIDER_CUSTOM3_BATCH_SIZE = 100
EMBEDDING_PROVIDER_SIMILARITY_BATCH_SIZE = 64

# Logging Configuration
LOG_LEVEL = debug
LOG_FORMAT = json

# Search Configuration
SEARCH_MOCK_MODE = false

# Project Naming Configuration
# Qdrant Collection Naming
PROJECT_QDRANT_DEFAULT_COLLECTION = code-snippets
PROJECT_QDRANT_NAMING_PATTERN = {projectId}

# Nebula Space Naming
PROJECT_NEBULA_DEFAULT_SPACE = test_space
PROJECT_NEBULA_NAMING_PATTERN = {projectId}

# Hot Reload Configuration
HOT_RELOAD_ENABLED = true
HOT_RELOAD_DEBOUNCE_INTERVAL = 500
HOT_RELOAD_MAX_FILE_SIZE = 512000
HOT_RELOAD_MAX_CONCURRENT_PROJECTS = 5
HOT_RELOAD_ENABLE_DETAILED_LOGGING = false
HOT_RELOAD_ERROR_MAX_RETRIES = 3
HOT_RELOAD_ERROR_ALERT_THRESHOLD = 5
HOT_RELOAD_ERROR_AUTO_RECOVERY = true

# ==================== Segmentation Configuration ====================
# Code splitting/chunking configuration for AST processing

# Segmentation mode: default, high-performance, high-quality
SEGMENTATION_MODE = default

# Global chunking settings
SEGMENTATION_MIN_CHUNK_SIZE = 50
SEGMENTATION_MAX_CHUNK_SIZE = 2000
SEGMENTATION_CHUNK_OVERLAP = 200

# Performance settings
SEGMENTATION_MAX_FILE_SIZE = 512000
SEGMENTATION_MAX_PARSE_TIME = 5000
SEGMENTATION_ENABLE_CACHING = true
SEGMENTATION_MAX_CACHE_SIZE = 1000
SEGMENTATION_ENABLE_PARALLEL = true
SEGMENTATION_PARALLEL_THREADS = 4
